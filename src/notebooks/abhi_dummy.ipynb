{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c503c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INSTALLING REQUIRED PACKAGES ===\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (4.1.0)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from umap-learn) (0.59.1)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.42.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\abhishek\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: pynndescent, umap-learn\n",
      "Successfully installed pynndescent-0.5.13 umap-learn-0.5.7\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "print(\"=== INSTALLING REQUIRED PACKAGES ===\")\n",
    "!pip install sentence-transformers umap-learn matplotlib\n",
    "!pip install --quiet \"umap-learn[plot]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b7c6bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\__init__.py:14\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     CrossEncoder,\n\u001b[0;32m     16\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     17\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfit_mixin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData, generate_model_card\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     cross_encoder_init_args_decorator,\n\u001b[0;32m     35\u001b[0m     cross_encoder_predict_rank_args_decorator,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\fit_mixin.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\datasets\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\SentenceTransformer.py:34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torch_npu_available\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\model_card.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This script generates content-based embeddings for the blog dataset.\n",
    "\n",
    "It performs the following steps:\n",
    "1.  Loads the preprocessed blog metadata.\n",
    "2.  Creates a combined text field from the blog's title, content, and topic.\n",
    "3.  Uses a pre-trained Sentence Transformer model to generate embeddings for this\n",
    "    combined text.\n",
    "4.  Saves the generated embeddings and the corresponding blog IDs to a pickle\n",
    "    file in the 'models' directory.\n",
    "5.  Includes a function to demonstrate how to use the saved embeddings to find\n",
    "    similar blogs.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For better display in Colab\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SETUP AND CONFIGURATION ---\n",
    "\n",
    "print(\"=== SCRIPT START: Content-Based Model Generation ===\")\n",
    "\n",
    "# Define base paths to locate data and save models\n",
    "# Assumes the script is run from the 'src' directory\n",
    "BASE_PATH = os.path.dirname(os.getcwd())\n",
    "PROCESSED_DATA_PATH = os.path.join(BASE_PATH, \"data\", \"processed\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
    "\n",
    "# Define file paths for input and output\n",
    "INPUT_BLOG_DATA_PATH = os.path.join(PROCESSED_DATA_PATH,\n",
    "                                    \"cleaned_blog_metadata.pkl\")\n",
    "OUTPUT_EMBEDDING_MODEL_PATH = os.path.join(MODELS_PATH, \"embedding_model.pkl\")\n",
    "\n",
    "# Ensure the 'models' directory exists\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    print(f\"Creating directory: {MODELS_PATH}\")\n",
    "    os.makedirs(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39add739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base directory: c:\\Users\\Abhishek\\Downloads\\EMLYON CLASSES\\PYTHON\\35. RECOMMENDATION SYSTEMS\\BlogRecommendation\n",
      "raw data directory: c:\\Users\\Abhishek\\Downloads\\EMLYON CLASSES\\PYTHON\\35. RECOMMENDATION SYSTEMS\\BlogRecommendation\\data\\raw\n",
      "processed data directory: c:\\Users\\Abhishek\\Downloads\\EMLYON CLASSES\\PYTHON\\35. RECOMMENDATION SYSTEMS\\BlogRecommendation\\data\\processed\n",
      "src directory: c:\\Users\\Abhishek\\Downloads\\EMLYON CLASSES\\PYTHON\\35. RECOMMENDATION SYSTEMS\\BlogRecommendation\\src\n",
      "current directory: c:\\Users\\Abhishek\\Downloads\\EMLYON CLASSES\\PYTHON\\35. RECOMMENDATION SYSTEMS\\BlogRecommendation\\src\\notebooks\n"
     ]
    }
   ],
   "source": [
    "base_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "rawdata_path = os.path.join(base_path, \"data\" ,\"raw\")\n",
    "processeddata_path = os.path.join(base_path, \"data\", \"processed\") \n",
    "if not os.path.exists(processeddata_path):\n",
    "    os.makedirs(processeddata_path)\n",
    "src_dir= os.path.join(base_path, \"src\")\n",
    "curr_path= os.getcwd()\n",
    "\n",
    "print(f\"base directory: {base_path}\")\n",
    "print(f\"raw data directory: {rawdata_path}\")\n",
    "print(f\"processed data directory: {processeddata_path}\")\n",
    "print(f\"src directory: {src_dir}\")\n",
    "print(f\"current directory: {curr_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f36790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape : (200140, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "blog_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "blog_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_img",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scrape_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "scrape_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "author_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "df7bab3b-186a-4aca-928e-a71967e2f92c",
       "rows": [
        [
         "0",
         "9025",
         "11",
         "3.5",
         "5960",
         "How I became a Frontend Developer",
         "A little bit of background about me: as a teen, I grew up wanting to be a football player like most of my friends did and I wasn’t really into computers till I hit 17 when I started ICT at ALevels. My first website was built on Microsoft FrontPage and…",
         "https://medium.com/@steven.dornan93/how-i-became-a-frontend-developer-63b9736d4ed9?source=topics_v2---------4-84--------------------6748c57a_21d2_49e5_821d_2efbbf58c2a0-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*n6O8YJ1R6mgrgjcOjYckPg.png",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Steven Dornan"
        ],
        [
         "1",
         "9320",
         "11",
         "5.0",
         "6155",
         "Writing an Algorithm to Calculate Article Read Length",
         "You have probably noticed a read-time number underneath article titles while scrolling through your favorite news source. It is an important metric for readers as it allows them to determine how much time they are devoting to an article, and marks content in a way that allows for filtering and…",
         "https://medium.com/@dpericich/writing-an-algorithm-to-calculate-article-read-length-b45181f16a79?source=topics_v2---------84-84--------------------ca1ed544_badf_4501_95dd_e8b83ffa96f9-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/0*a_Uwp9mDv0IkZG9v",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Daniel Pericich"
        ],
        [
         "2",
         "9246",
         "11",
         "3.5",
         "6114",
         "Diving into HTML and the Tools of the Trade",
         "It’s been an incredible first week as a Bytewise Frontend Development Fellow, and I am thrilled to share all that I have learned with you all! During the first week of my fellowship, I had the opportunity to dive into the basics of web development and learn about the essential…",
         "https://medium.com/@muhammadnaeemtahir/diving-into-html-and-the-tools-of-the-trade-4e3c8c84ab3?source=topics_v2---------2-84--------------------98fda2bd_6ce9_4ec4_9db8_fae3b8a9def5-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*KkI2d3PGEEffL7Y2w_xNsg.png",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Muhammad Naeem Tahir"
        ],
        [
         "3",
         "9431",
         "11",
         "5.0",
         "2386",
         "Learning Too Many Programming Languages at Once?",
         "Learning too many programming languages at once can be overwhelming and counterproductive. While it’s good to have a broad understanding of different programming languages, trying to learn too many languages simultaneously can lead to confusion and difficulty in retaining information. When learning a new programming language, it’s important to devote…",
         "https://medium.com/@mohit-singh/learning-too-many-programming-languages-at-once-f10e8dfe7131?source=topics_v2---------201-84--------------------6cc98ce5_ef90_4b09_be34_e025f665b004-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/0*MNTYPSYdtETslxi2.jpeg",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Mohit Singh"
        ],
        [
         "4",
         "875",
         "11",
         "2.0",
         "699",
         "Cryptocurrency Regulations: A Tug of War Between Investors and Bureaucrats",
         "Once upon a time in the wild, wild world of cryptocurrencies, outlaws reigned supreme, and regulations were as rare as an unopened email from your uncle boasting about his latest get-rich-quick scheme. But alas, that time has come to an end, my friend, and with it, the age of cryptocurrency…",
         "https://medium.com/@Juan_In_The_Chain/cryptocurrency-regulations-a-tug-of-war-between-investors-and-bureaucrats-dc5101e7de77?source=topics_v2---------176-84--------------------275bd009_3a38_4c4a_98d0_689f1e73acc5-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*Roeppy1F1dXBELSl2U1w3Q.png",
         "blockchain",
         "2023-04-03 06:06:20",
         "2023-04-03",
         "Juan In The Chain"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>author_id</th>\n",
       "      <th>blog_title</th>\n",
       "      <th>blog_content</th>\n",
       "      <th>blog_link</th>\n",
       "      <th>blog_img</th>\n",
       "      <th>topic</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9025</td>\n",
       "      <td>11</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5960</td>\n",
       "      <td>How I became a Frontend Developer</td>\n",
       "      <td>A little bit of background about me: as a teen...</td>\n",
       "      <td>https://medium.com/@steven.dornan93/how-i-beca...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Steven Dornan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9320</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6155</td>\n",
       "      <td>Writing an Algorithm to Calculate Article Read...</td>\n",
       "      <td>You have probably noticed a read-time number u...</td>\n",
       "      <td>https://medium.com/@dpericich/writing-an-algor...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Daniel Pericich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9246</td>\n",
       "      <td>11</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6114</td>\n",
       "      <td>Diving into HTML and the Tools of the Trade</td>\n",
       "      <td>It’s been an incredible first week as a Bytewi...</td>\n",
       "      <td>https://medium.com/@muhammadnaeemtahir/diving-...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Muhammad Naeem Tahir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9431</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2386</td>\n",
       "      <td>Learning Too Many Programming Languages at Once?</td>\n",
       "      <td>Learning too many programming languages at onc...</td>\n",
       "      <td>https://medium.com/@mohit-singh/learning-too-m...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Mohit Singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>699</td>\n",
       "      <td>Cryptocurrency Regulations: A Tug of War Betwe...</td>\n",
       "      <td>Once upon a time in the wild, wild world of cr...</td>\n",
       "      <td>https://medium.com/@Juan_In_The_Chain/cryptocu...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>blockchain</td>\n",
       "      <td>2023-04-03 06:06:20</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Juan In The Chain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  user_id  ratings  author_id  \\\n",
       "0     9025       11      3.5       5960   \n",
       "1     9320       11      5.0       6155   \n",
       "2     9246       11      3.5       6114   \n",
       "3     9431       11      5.0       2386   \n",
       "4      875       11      2.0        699   \n",
       "\n",
       "                                          blog_title  \\\n",
       "0                  How I became a Frontend Developer   \n",
       "1  Writing an Algorithm to Calculate Article Read...   \n",
       "2        Diving into HTML and the Tools of the Trade   \n",
       "3   Learning Too Many Programming Languages at Once?   \n",
       "4  Cryptocurrency Regulations: A Tug of War Betwe...   \n",
       "\n",
       "                                        blog_content  \\\n",
       "0  A little bit of background about me: as a teen...   \n",
       "1  You have probably noticed a read-time number u...   \n",
       "2  It’s been an incredible first week as a Bytewi...   \n",
       "3  Learning too many programming languages at onc...   \n",
       "4  Once upon a time in the wild, wild world of cr...   \n",
       "\n",
       "                                           blog_link  \\\n",
       "0  https://medium.com/@steven.dornan93/how-i-beca...   \n",
       "1  https://medium.com/@dpericich/writing-an-algor...   \n",
       "2  https://medium.com/@muhammadnaeemtahir/diving-...   \n",
       "3  https://medium.com/@mohit-singh/learning-too-m...   \n",
       "4  https://medium.com/@Juan_In_The_Chain/cryptocu...   \n",
       "\n",
       "                                            blog_img            topic  \\\n",
       "0  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "1  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "2  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "3  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "4  https://miro.medium.com/v2/resize:fill:140:140...       blockchain   \n",
       "\n",
       "          scrape_time scrape_date           author_name  \n",
       "0 2023-04-04 08:53:52  2023-04-04         Steven Dornan  \n",
       "1 2023-04-04 08:53:52  2023-04-04       Daniel Pericich  \n",
       "2 2023-04-04 08:53:52  2023-04-04  Muhammad Naeem Tahir  \n",
       "3 2023-04-04 08:53:52  2023-04-04           Mohit Singh  \n",
       "4 2023-04-03 06:06:20  2023-04-03     Juan In The Chain  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape : (194727, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "blog_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "blog_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_img",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scrape_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "scrape_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "author_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fe5803d3-e646-406c-ac39-484953e7da29",
       "rows": [
        [
         "0",
         "9025",
         "11",
         "3.5",
         "5960",
         "How I became a Frontend Developer",
         "A little bit of background about me: as a teen, I grew up wanting to be a football player like most of my friends did and I wasn’t really into computers till I hit 17 when I started ICT at ALevels. My first website was built on Microsoft FrontPage and…",
         "https://medium.com/@steven.dornan93/how-i-became-a-frontend-developer-63b9736d4ed9?source=topics_v2---------4-84--------------------6748c57a_21d2_49e5_821d_2efbbf58c2a0-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*n6O8YJ1R6mgrgjcOjYckPg.png",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Steven Dornan"
        ],
        [
         "1",
         "9320",
         "11",
         "5.0",
         "6155",
         "Writing an Algorithm to Calculate Article Read Length",
         "You have probably noticed a read-time number underneath article titles while scrolling through your favorite news source. It is an important metric for readers as it allows them to determine how much time they are devoting to an article, and marks content in a way that allows for filtering and…",
         "https://medium.com/@dpericich/writing-an-algorithm-to-calculate-article-read-length-b45181f16a79?source=topics_v2---------84-84--------------------ca1ed544_badf_4501_95dd_e8b83ffa96f9-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/0*a_Uwp9mDv0IkZG9v",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Daniel Pericich"
        ],
        [
         "2",
         "9246",
         "11",
         "3.5",
         "6114",
         "Diving into HTML and the Tools of the Trade",
         "It’s been an incredible first week as a Bytewise Frontend Development Fellow, and I am thrilled to share all that I have learned with you all! During the first week of my fellowship, I had the opportunity to dive into the basics of web development and learn about the essential…",
         "https://medium.com/@muhammadnaeemtahir/diving-into-html-and-the-tools-of-the-trade-4e3c8c84ab3?source=topics_v2---------2-84--------------------98fda2bd_6ce9_4ec4_9db8_fae3b8a9def5-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*KkI2d3PGEEffL7Y2w_xNsg.png",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Muhammad Naeem Tahir"
        ],
        [
         "3",
         "9431",
         "11",
         "5.0",
         "2386",
         "Learning Too Many Programming Languages at Once?",
         "Learning too many programming languages at once can be overwhelming and counterproductive. While it’s good to have a broad understanding of different programming languages, trying to learn too many languages simultaneously can lead to confusion and difficulty in retaining information. When learning a new programming language, it’s important to devote…",
         "https://medium.com/@mohit-singh/learning-too-many-programming-languages-at-once-f10e8dfe7131?source=topics_v2---------201-84--------------------6cc98ce5_ef90_4b09_be34_e025f665b004-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/0*MNTYPSYdtETslxi2.jpeg",
         "web-development",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Mohit Singh"
        ],
        [
         "4",
         "875",
         "11",
         "2.0",
         "699",
         "Cryptocurrency Regulations: A Tug of War Between Investors and Bureaucrats",
         "Once upon a time in the wild, wild world of cryptocurrencies, outlaws reigned supreme, and regulations were as rare as an unopened email from your uncle boasting about his latest get-rich-quick scheme. But alas, that time has come to an end, my friend, and with it, the age of cryptocurrency…",
         "https://medium.com/@Juan_In_The_Chain/cryptocurrency-regulations-a-tug-of-war-between-investors-and-bureaucrats-dc5101e7de77?source=topics_v2---------176-84--------------------275bd009_3a38_4c4a_98d0_689f1e73acc5-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*Roeppy1F1dXBELSl2U1w3Q.png",
         "blockchain",
         "2023-04-03 06:06:20",
         "2023-04-03",
         "Juan In The Chain"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>author_id</th>\n",
       "      <th>blog_title</th>\n",
       "      <th>blog_content</th>\n",
       "      <th>blog_link</th>\n",
       "      <th>blog_img</th>\n",
       "      <th>topic</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9025</td>\n",
       "      <td>11</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5960</td>\n",
       "      <td>How I became a Frontend Developer</td>\n",
       "      <td>A little bit of background about me: as a teen...</td>\n",
       "      <td>https://medium.com/@steven.dornan93/how-i-beca...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Steven Dornan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9320</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6155</td>\n",
       "      <td>Writing an Algorithm to Calculate Article Read...</td>\n",
       "      <td>You have probably noticed a read-time number u...</td>\n",
       "      <td>https://medium.com/@dpericich/writing-an-algor...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Daniel Pericich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9246</td>\n",
       "      <td>11</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6114</td>\n",
       "      <td>Diving into HTML and the Tools of the Trade</td>\n",
       "      <td>It’s been an incredible first week as a Bytewi...</td>\n",
       "      <td>https://medium.com/@muhammadnaeemtahir/diving-...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Muhammad Naeem Tahir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9431</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2386</td>\n",
       "      <td>Learning Too Many Programming Languages at Once?</td>\n",
       "      <td>Learning too many programming languages at onc...</td>\n",
       "      <td>https://medium.com/@mohit-singh/learning-too-m...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>web-development</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Mohit Singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>699</td>\n",
       "      <td>Cryptocurrency Regulations: A Tug of War Betwe...</td>\n",
       "      <td>Once upon a time in the wild, wild world of cr...</td>\n",
       "      <td>https://medium.com/@Juan_In_The_Chain/cryptocu...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>blockchain</td>\n",
       "      <td>2023-04-03 06:06:20</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Juan In The Chain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  user_id  ratings  author_id  \\\n",
       "0     9025       11      3.5       5960   \n",
       "1     9320       11      5.0       6155   \n",
       "2     9246       11      3.5       6114   \n",
       "3     9431       11      5.0       2386   \n",
       "4      875       11      2.0        699   \n",
       "\n",
       "                                          blog_title  \\\n",
       "0                  How I became a Frontend Developer   \n",
       "1  Writing an Algorithm to Calculate Article Read...   \n",
       "2        Diving into HTML and the Tools of the Trade   \n",
       "3   Learning Too Many Programming Languages at Once?   \n",
       "4  Cryptocurrency Regulations: A Tug of War Betwe...   \n",
       "\n",
       "                                        blog_content  \\\n",
       "0  A little bit of background about me: as a teen...   \n",
       "1  You have probably noticed a read-time number u...   \n",
       "2  It’s been an incredible first week as a Bytewi...   \n",
       "3  Learning too many programming languages at onc...   \n",
       "4  Once upon a time in the wild, wild world of cr...   \n",
       "\n",
       "                                           blog_link  \\\n",
       "0  https://medium.com/@steven.dornan93/how-i-beca...   \n",
       "1  https://medium.com/@dpericich/writing-an-algor...   \n",
       "2  https://medium.com/@muhammadnaeemtahir/diving-...   \n",
       "3  https://medium.com/@mohit-singh/learning-too-m...   \n",
       "4  https://medium.com/@Juan_In_The_Chain/cryptocu...   \n",
       "\n",
       "                                            blog_img            topic  \\\n",
       "0  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "1  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "2  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "3  https://miro.medium.com/v2/resize:fill:140:140...  web-development   \n",
       "4  https://miro.medium.com/v2/resize:fill:140:140...       blockchain   \n",
       "\n",
       "          scrape_time scrape_date           author_name  \n",
       "0 2023-04-04 08:53:52  2023-04-04         Steven Dornan  \n",
       "1 2023-04-04 08:53:52  2023-04-04       Daniel Pericich  \n",
       "2 2023-04-04 08:53:52  2023-04-04  Muhammad Naeem Tahir  \n",
       "3 2023-04-04 08:53:52  2023-04-04           Mohit Singh  \n",
       "4 2023-04-03 06:06:20  2023-04-03     Juan In The Chain  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df shape : (5413, 12)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "blog_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ratings",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "blog_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "blog_img",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "scrape_time",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "scrape_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "author_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e0cf037e-2973-49dd-9a30-cbaa8bc467a1",
       "rows": [
        [
         "0",
         "2080",
         "24",
         "2.0",
         "1661",
         "Convolution: The Pixel Perfect Technique Behind CNNs",
         "Definition Convolution is a fundamental operation in convolutional neural networks (CNNs). It is a mathematical operation used to process image data by applying a set of filters or kernels to the input image. The convolution operation involves taking a small matrix, called the kernel or filter, and sliding it over the…",
         "https://medium.com/@aatish_kayyath/convolution-the-pixel-perfect-technique-behind-cnns-c4c3b464a816?source=topics_v2---------59-84--------------------b2924520_43a5_4fae_bb33_8cd385fe0103-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*4u2UKWBK1OWlOwnabIQnfQ.jpeg",
         "image-processing",
         "2023-04-03 06:43:15",
         "2023-04-03",
         "Aatish Kayyath"
        ],
        [
         "1",
         "2152",
         "24",
         "3.5",
         "1704",
         "Intel Image Classification using CNNs and different Optimizers",
         "I am reading “Deep Learning with Python” by François Chollet, and as a beginner in Deep Learning, I decided to apply what I learned to a Kaggle dataset. I chose the Intel Image Classification because it is a basic dataset for applying my newly founded skills. About the Intel Image Classification Dataset: Around 25000 images each…",
         "https://medium.com/@shanmuka.sadhu/intel-image-classification-using-cnns-and-different-optimizers-8ba8b1ca514e?source=topics_v2---------135-84--------------------868179e5_627d_4438_8cdc_cb2d4fcfaaf6-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*VNvV5UDdWrQ-waltOLZL7A.png",
         "image-processing",
         "2023-04-03 06:43:15",
         "2023-04-03",
         "Shanmuka Sadhu"
        ],
        [
         "2",
         "2137",
         "24",
         "5.0",
         "1696",
         "Can AI save bad scans?",
         "The starting point for any kind of document digitization, whether done by hand or through sophisticated text recognition algorithms, is a good-quality image. Take a look at the one below. It is a scan of the US declaration of independence — but not of the original. The real one has…",
         "https://medium.com/transkribus/can-ai-save-bad-scans-5e692e4bc8d2?source=topics_v2---------116-84--------------------820163bf_792f_49cb_81f7_623293cd5696-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/0*sZM4yD_1mxAaUhwF.png",
         "image-processing",
         "2023-04-03 06:43:15",
         "2023-04-03",
         "Fiona Park"
        ],
        [
         "3",
         "2215",
         "24",
         "0.5",
         "1662",
         "How can i observe a 3 dimensional matrix(hdr) using pcolor command?",
         "I have with me, file={'img1.jpg','img2.jpg','img3.jpg','img4.jpg','img5.jpg'};\nhdr = makehdr(file); hdr is 1728x2592x3 single matrix I want to display this image file in pseudocolor. my aim is to get the light intensity values. What shall i do? NOTE:- Matlabsolutions.com provide latest MatLab Homework Help,MatLab Assignment Help , Finance Assignment Help for students…",
         "https://medium.com/@technicalsource9/how-can-i-observe-a-3-dimensional-matrix-hdr-using-pcolor-command-ea87abcb2825?source=topics_v2---------198-84--------------------1e413cc0_70e9_4ff1_92ee_9d9463b5605c-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*Js7Vum23VDHIxXSaxDrD0w.jpeg",
         "image-processing",
         "2023-04-03 06:43:15",
         "2023-04-03",
         "Technical Source"
        ],
        [
         "4",
         "7105",
         "24",
         "5.0",
         "4195",
         "Overview of Autoencoders",
         "Autoencoders are a type of neural network that can be used to learn a compressed representation of a dataset. They consist of two main parts: an encoder, which maps the input data to a lower-dimensional representation, and a decoder, which maps the lower-dimensional representation back to the original dimensionality. There…",
         "https://medium.com/@dongreanay/overview-of-autoencoders-52c777418937?source=topics_v2---------218-84--------------------73aa21e9_e1ac_47f3_8692_255051b49994-------17",
         "https://miro.medium.com/v2/resize:fill:140:140/1*4vpgF2V_i4U37wftGfgUXg.jpeg",
         "image-processing",
         "2023-04-04 08:53:52",
         "2023-04-04",
         "Anay Dongre"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blog_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>author_id</th>\n",
       "      <th>blog_title</th>\n",
       "      <th>blog_content</th>\n",
       "      <th>blog_link</th>\n",
       "      <th>blog_img</th>\n",
       "      <th>topic</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2080</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1661</td>\n",
       "      <td>Convolution: The Pixel Perfect Technique Behin...</td>\n",
       "      <td>Definition Convolution is a fundamental operat...</td>\n",
       "      <td>https://medium.com/@aatish_kayyath/convolution...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>image-processing</td>\n",
       "      <td>2023-04-03 06:43:15</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Aatish Kayyath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2152</td>\n",
       "      <td>24</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1704</td>\n",
       "      <td>Intel Image Classification using CNNs and diff...</td>\n",
       "      <td>I am reading “Deep Learning with Python” by Fr...</td>\n",
       "      <td>https://medium.com/@shanmuka.sadhu/intel-image...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>image-processing</td>\n",
       "      <td>2023-04-03 06:43:15</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Shanmuka Sadhu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2137</td>\n",
       "      <td>24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1696</td>\n",
       "      <td>Can AI save bad scans?</td>\n",
       "      <td>The starting point for any kind of document di...</td>\n",
       "      <td>https://medium.com/transkribus/can-ai-save-bad...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>image-processing</td>\n",
       "      <td>2023-04-03 06:43:15</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Fiona Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2215</td>\n",
       "      <td>24</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1662</td>\n",
       "      <td>How can i observe a 3 dimensional matrix(hdr) ...</td>\n",
       "      <td>I have with me, file={'img1.jpg','img2.jpg','i...</td>\n",
       "      <td>https://medium.com/@technicalsource9/how-can-i...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>image-processing</td>\n",
       "      <td>2023-04-03 06:43:15</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Technical Source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7105</td>\n",
       "      <td>24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4195</td>\n",
       "      <td>Overview of Autoencoders</td>\n",
       "      <td>Autoencoders are a type of neural network that...</td>\n",
       "      <td>https://medium.com/@dongreanay/overview-of-aut...</td>\n",
       "      <td>https://miro.medium.com/v2/resize:fill:140:140...</td>\n",
       "      <td>image-processing</td>\n",
       "      <td>2023-04-04 08:53:52</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Anay Dongre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blog_id  user_id  ratings  author_id  \\\n",
       "0     2080       24      2.0       1661   \n",
       "1     2152       24      3.5       1704   \n",
       "2     2137       24      5.0       1696   \n",
       "3     2215       24      0.5       1662   \n",
       "4     7105       24      5.0       4195   \n",
       "\n",
       "                                          blog_title  \\\n",
       "0  Convolution: The Pixel Perfect Technique Behin...   \n",
       "1  Intel Image Classification using CNNs and diff...   \n",
       "2                             Can AI save bad scans?   \n",
       "3  How can i observe a 3 dimensional matrix(hdr) ...   \n",
       "4                           Overview of Autoencoders   \n",
       "\n",
       "                                        blog_content  \\\n",
       "0  Definition Convolution is a fundamental operat...   \n",
       "1  I am reading “Deep Learning with Python” by Fr...   \n",
       "2  The starting point for any kind of document di...   \n",
       "3  I have with me, file={'img1.jpg','img2.jpg','i...   \n",
       "4  Autoencoders are a type of neural network that...   \n",
       "\n",
       "                                           blog_link  \\\n",
       "0  https://medium.com/@aatish_kayyath/convolution...   \n",
       "1  https://medium.com/@shanmuka.sadhu/intel-image...   \n",
       "2  https://medium.com/transkribus/can-ai-save-bad...   \n",
       "3  https://medium.com/@technicalsource9/how-can-i...   \n",
       "4  https://medium.com/@dongreanay/overview-of-aut...   \n",
       "\n",
       "                                            blog_img             topic  \\\n",
       "0  https://miro.medium.com/v2/resize:fill:140:140...  image-processing   \n",
       "1  https://miro.medium.com/v2/resize:fill:140:140...  image-processing   \n",
       "2  https://miro.medium.com/v2/resize:fill:140:140...  image-processing   \n",
       "3  https://miro.medium.com/v2/resize:fill:140:140...  image-processing   \n",
       "4  https://miro.medium.com/v2/resize:fill:140:140...  image-processing   \n",
       "\n",
       "          scrape_time scrape_date       author_name  \n",
       "0 2023-04-03 06:43:15  2023-04-03    Aatish Kayyath  \n",
       "1 2023-04-03 06:43:15  2023-04-03    Shanmuka Sadhu  \n",
       "2 2023-04-03 06:43:15  2023-04-03        Fiona Park  \n",
       "3 2023-04-03 06:43:15  2023-04-03  Technical Source  \n",
       "4 2023-04-04 08:53:52  2023-04-04       Anay Dongre  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df= pd.read_pickle(os.path.join(processeddata_path, \"cleaned_blog_ratings.pkl\"))\n",
    "train_df=pd.read_pickle(os.path.join(processeddata_path, \"train_ratings.pkl\"))\n",
    "test_df=pd.read_pickle(os.path.join(processeddata_path, \"test_ratings.pkl\"))    \n",
    "\n",
    "print(f\"df shape : {df.shape}\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"train_df shape : {train_df.shape}\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(f\"test_df shape : {test_df.shape}\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3718104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200140 entries, 0 to 200139\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   blog_id       200140 non-null  int64         \n",
      " 1   user_id       200140 non-null  int64         \n",
      " 2   ratings       200140 non-null  float64       \n",
      " 3   author_id     200140 non-null  int64         \n",
      " 4   blog_title    200140 non-null  object        \n",
      " 5   blog_content  200140 non-null  object        \n",
      " 6   blog_link     200140 non-null  object        \n",
      " 7   blog_img      200140 non-null  object        \n",
      " 8   topic         200140 non-null  object        \n",
      " 9   scrape_time   200140 non-null  datetime64[ns]\n",
      " 10  scrape_date   200140 non-null  object        \n",
      " 11  author_name   200140 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(7)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
